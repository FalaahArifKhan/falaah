<!DOCTYPE HTML>
<html>
	<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Falaah Arif Khan</title>
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="" />
	<meta name="keywords" content="" />
	<meta name="author" content="" />

  <!-- Facebook and Twitter integration -->
	<meta property="og:title" content=""/>
	<meta property="og:image" content=""/>
	<meta property="og:url" content=""/>
	<meta property="og:site_name" content=""/>
	<meta property="og:description" content=""/>
	<meta name="twitter:title" content="" />
	<meta name="twitter:image" content="" />
	<meta name="twitter:url" content="" />
	<meta name="twitter:card" content="" />

	<!-- Place favicon.ico and apple-touch-icon.png in the root directory -->
	<link rel="shortcut icon" href="favicon.ico">

	<link href="https://fonts.googleapis.com/css?family=Quicksand:300,400,500,700" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Playfair+Display:400,400i,700" rel="stylesheet">
	
	<!-- Animate.css -->
	<link rel="stylesheet" href="css/animate.css">
	<!-- Icomoon Icon Fonts-->
	<link rel="stylesheet" href="css/icomoon.css">
	<!-- Bootstrap  -->
	<link rel="stylesheet" href="css/bootstrap.css">
	<!-- Flexslider  -->
	<link rel="stylesheet" href="css/flexslider.css">
	<!-- Flaticons  -->
	<link rel="stylesheet" href="fonts/flaticon/font/flaticon.css">
	<!-- Owl Carousel -->
	<link rel="stylesheet" href="css/owl.carousel.min.css">
	<link rel="stylesheet" href="css/owl.theme.default.min.css">
	<!-- Theme style  -->
	<link rel="stylesheet" href="css/style.css">

	<!-- Modernizr JS -->
	<script src="js/modernizr-2.6.2.min.js"></script>
	<!-- FOR IE9 below -->
	<!--[if lt IE 9]>
	<script src="js/respond.min.js"></script>
	<![endif]-->

	</head>
	<body>
	<div id="colorlib-page">
		<div class="container-wrap">
		<a href="#" class="js-colorlib-nav-toggle colorlib-nav-toggle" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar"><i></i></a>
		<aside id="colorlib-aside" role="complementary" class="border js-fullheight">
			<div class="text-center">
				<div class="author-img" style="background-image: url(images/about.png);"></div>
				<h1 id="colorlib-logo"><a href="index.html">Falaah Arif Khan</a></h1>
				<h6>  I do Science and create Art </h6>				
			</div>
			<nav id="colorlib-main-menu" role="navigation" class="navbar">
				<div id="navbar" class="collapse">
					<ul>
						<li class="active"><a href="#" data-nav-section="about">About</a></li>
						<li><a href="#" data-nav-section="news">News</a></li>
						<li><a href="#" data-nav-section="research">Research</a></li>
						<li><a href="#" data-nav-section="gallery">ML Comics</a></li>
						<li><a href="#" data-nav-section="blog">Stuff</a></li>
						<li><a href="#" data-nav-section="contact">Contact</a></li>
					</ul>
				</div>
			</nav>

			<div class="colorlib-footer">
				<p><small>&copy; <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
Copyright &copy;<script>document.write(new Date().getFullYear());</script> All rights reserved | This template is made with <i class="icon-heart" aria-hidden="true"></i> by <a href="https://colorlib.com" target="_blank">Colorlib</a>
<!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. --> 
			</div>

		</aside>

		<div id="colorlib-main">
			<section class="colorlib-about" data-section="about">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-12">
							<div class="row row-bottom-padded-sm animate-box" data-animate-effect="fadeInLeft">
								<div class="col-md-12">
									<div class="about-desc">
										<span class="heading-meta">About</span>
										<h2 class="colorlib-heading">Who Am I?</h2>
										<p><strong>Hi! I'm Falaah.</strong> I'm a Engineer/Scientist by training and an Artist by nature, broadly interested in reliable and "responsible" AI. Towards this end, I conduct fundamental research on "algorithmic fairness", and create scientific comics (and other artwork) to disseminate the nuances of this work in a way that is more accessible to a variety of (technical and non-technical) audiences.

										I'm currently a second-year PhD student at NYU's <a href="https://cds.nyu.edu"> Center for Data Science</a>, and an Artist-in-Residence at the <a href="http://airesponsibly.com/"> Center for Responsible AI (R/AI) </a>. I'm extremely lucky to get to do two things I absolutely love to do: fundamental research and creating scientific comics!
 
										<p>At NYU, I'm advised by the inimitable <a href="http://stoyanovich.org/">Prof Julia Stoyanovich</a>. Broadly, we work on the societal impacts of AI, and the normative and technical foundations of algorithmic fairness. Check out the "Research" section of this page for more details about ongoing projects. Excitingly, Julia and I also create several <a href="https://dataresponsibly.github.io/comics/">comic series</a> at NYU R/AI: the 'Data, Responsibly' Comic series, targeted at a semi-technical audience, and the 'We are AI' comics, created for the general public. We recently did a deep dive on the accessibility of the 'We are AI' comics through a series of roundtables with accessibility experts as part of the <a href="https://airesponsibly.net/2023/04/22/all-aboard-a-primer-on-making-public-ai-education-accessible/"> All Aboard! Project </a>. These discussions were incredibly valuable, and inform the comics that I am currently creating. Stay tuned for details on new comics! </p>
										
										<p>During the pandemic, I also co-created the <a href="https://github.com/acmi-lab/superheroes-deep-learning">'Superheroes of Deep Learning'</a> comics with <a href="http://zacklipton.com/">Prof Zack Lipton</a>, which documents the thrilling tales and heroic feats of ML's larger-than-life champions. </p>
										
										<p> Before starting my PhD, I did an Artist Residency at the Montreal AI Ethics Institute. My visual essay, <a href="https://ai-ethics.github.io/decoded-reality/intro.html"> 'Decoded Reality'</a>, is an artistic exploration of the power dynamics that shape the design, development and deployment of ML systems. We present visual interpretations of how algorithmic interventions manifest in society, with the hope of provoking the designers of these systems to think critically about the socio-political underpinnings of each step of the engineering process. </p>

										<p>Previously, I worked as a Research Engineer at Dell EMC, Bangalore where I designed and built data-driven models for Identity and Access Management (IAM). My research focused on behavior-based Authentication, online learning for CAPTCHA design and graph signal processing for dynamic threat modelling. For more details on these projects, check out the "Research" section, or my CV (linked at the end of this section). </p>
										
										<p>My work in the industry showed me firsthand the pressing challenges of building 'production-ready' models. Contrary to the media narrative around AI, this technology is far from being 'sophisticated' --- we are yet to have figured out how to build models that are robust, reliable and designed to thrive in the wild. These challenges have informed my interest to explore the foundations of generalization, robustness and fairness. One interesting way to explore these questions is by critically assessing how AI impacts, and is in turn impacted by, the underlying social setting in which it was formulated. </p>
										
										<p> <a href="documents/Academic_CV.pdf">Curriculum Vitae</a> &emsp; <a href="https://scholar.google.com/citations?hl=en&user=53O3iRgAAAAJ&view_op=list_works&sortby=pubdate">Google Scholar</a></p>
									</div>
								</div>
							</div>
						</div>
					</div>
				</div>
			</section>

			<section class="colorlib-about" data-section="news">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-12">
							<div class="row row-bottom-padded-sm animate-box" data-animate-effect="fadeInLeft">
								<div class="col-md-12">
									<div class="news-desc">
										<span class="heading-meta">News</span>
										<h2 class="colorlib-heading">News</h2>

										<p>  Summer 2023: Co-facilitating the third offering of the <a href="https://dataresponsibly.github.io/we-are-ai/">'We Are AI'</a> public education course, to NYU librarians and non-academic staff! 

										<p> March 2023: Our work on the <a href="https://ssc.io/pdf/demodq.pdf"> effect of automated data cleaning on model fairness </a> has been accepted to the <a href="https://icde2023.ics.uci.edu/papers-special-track/"> Special Track at IEEE ICDE'23</a>!

										<p> October 2022: Our work on <a href="https://dl.acm.org/doi/abs/10.1145/3551624.3555303"> Fairness as Equal Opportunity </a> has been accepted to <a href="https://eaamo.org/#home"> ACM EAAMO'22 </a> for an Oral presentation! Watch the recording <a href="https://youtu.be/wIjcniWMElU">here.</a>

										<p> October 2022: Over the summer, the lovely folks over at the Civic Software Foundation commissioned a bunch of artwork for their newly re-vamped <a href="https://civicsoftwarefoundation.org">website</a>! Check it out, and find out more about the awesome work they do :)

										<p> September 2022: Our <a href="https://lbynum.github.io/interactive-causal-inference/">Interactive Introduction to Causal Inference</a> was accepted to the <a href="http://visxai.io">VISxAI Workshop</a> at IEEE VIS!

										<p> Aug 2022: Our paper on <a href="https://link.springer.com/article/10.1007/s10618-022-00861-0">Stability Auditing of Personality Prediction AI</a> was accepted to the Special Edition on Fairness and Bias of the Data Mining and Knowledge Discovery Journal! 

										<p> Summer 2022: We (<a href="https://airesponsibly.net">R/AI</a>) ran a 6-week summer research program in collaboration with the Ukranian Catholic University! #ScienceForUkraine. Check out the final project showcase <a href="https://airesponsibly.net/2022/09/26/nyu-r-ai-summer-research-program-2022/">here</a>!

										<p> July 2022: Giving D&I talks at IEEE MDM 2022 <a href="https://www.youtube.com/embed/ZWdgiF-940A"> (Video) </a> and ACM DEBS 2022 <a href="https://www.youtube.com/watch?v=c8jtDqCWYjU"> (Video) </a>!

										<p> September 2021: Started my PhD at NYU ! </p>

										<p> August 2021: New Superheroes of Deep Learning comic <a href="https://www.approximatelycorrect.com/2021/08/10/superheroes-of-deep-learning-vol-2-machine-learning-for-healthcare/">'Machine Learning for Healthcare'</a> is out now!

										<p> May-June 2021:  We just released a brand new, public-facing comic series, titled <a href="https://dataresponsibly.github.io/we-are-ai/comics/">'We are AI'</a>! It's a 5-volume primer on AI, blending the social, the legal and the technical, for anyone and everyone, and it accompanies <a href="https://airesponsibly.com/"> R/AI</a>'s new <a href="https://dataresponsibly.github.io/we-are-ai/">public education course</a> of the same name.

										<p> April 2021: Giving an invited talk titled "It's funny because it's true: confronting ML catechisms" at the <a href="https://rethinkingmlpapers.github.io/">'Rethinking ML Papers'</a> Workshop @ICLR 2021! Video recording <a href="https://slideslive.com/38956531">here.</a> (My talk starts at ~2:48:00)

										<p> April 2021: 'Fairness and Friends' has been accepted as an exhibit to the <a href="https://rethinkingmlpapers.github.io/papers/">'Rethinking ML Papers'</a> Workshop @ICLR 2021! Video explainer <a href="https://www.youtube.com/watch?v=aRpB57fd4YU"> here. </a> 

										<p> March 2021: Hosting <a href="https://schedule.mozillafestival.org/session/NWWNHA-1"> 'Decoded Reality' </a> - a collaborative, community brainstorm session about the role of Power in the creation of Responsible AI, at <a href="https://www.mozillafestival.org/en/"> MozFest 2021 </a>, based on <a href="https://ai-ethics.github.io/decoded-reality/intro.html"> my visual essay </a> of the same name!
										
										<p> March 2021: Presenting <a href="https://facctconference.org/2021/acceptedtuts.html#Friends"> 'Fairness and Friends' </a> - a translation tutorial that bridges scholarship from political philosophy and fair-ML - with Julia Stoyanovich and Eleni Manis, at ACM FAccT 2021! Recording is available <a href="https://www.youtube.com/watch?v=GiI6-tVYFoA"> here. </a> 
										
										<p> Feb 2021: Data, Responsibly Comics Vol 2: <a href="https://dataresponsibly.github.io/comics/vol2/fairness_en.pdf">'Fairness and Friends'</a> is out now!
										
										<p> Jan 2021: RDS Comics, Vol 1: 'Mirror, Mirror' has been translated into <a href="https://dataresponsibly.github.io/comics/vol1/mirror_fr.pdf"> French!!! </a>
 
										<p> Dec 2020: Facilitating the MAIEI x RAIN-Africa collaboration <a href="https://www.eventbrite.ca/e/perspectives-on-the-future-of-responsible-ai-in-africa-tickets-130080848319#"> 'Perspectives on the future of Responsible AI in Africa' </a> workshop. </a>
										
										<p> Dec 2020: The <a href="https://dataresponsibly.github.io/comics/vol1/mirror_fr.pdf"> Spanish edition </a> of RDS Comics, Volume 1: 'Mirror, Mirror' is out now!!!
										
										<p> Nov 2020: Facilitating the <a href="https://www.eventbrite.com/e/ai4good-x-maiei-privacy-in-artificial-intelligence-tickets-127902197917?utm-medium=discovery&utm-campaign=social&utm-content=attendeeshare&aff=escb&utm-source=cp&utm-term=listing"> 'Privacy in AI' Workshop </a>, by MAIEI and the AI4Good Lab
										
										<p> Nov 2020: Excited to be speaking at the <a href="https://www.facebook.com/events/1123723731398684/?active_tab=about"> 'Ethics in AI Panel' </a> by the McGill AI Society
										
										<p> Nov 2020: Giving an invited talk on 'Ethics in AI', based off of <a href="https://ai-ethics.github.io/decoded-reality/intro.html"> Decoded Reality</a>, at the <a href="https://techaidemontreal.org/2020-ai-conference-and-hackathon"> TechAide Montreal AI4Good Conference + Hackathon </a>

										<p> Nov 2020: Speaking about our 'Data, Responsibly' Comic books at the <a href="https://riipl.rutgers.edu/2020/11/10/riipl-algorithmic-justice-webinar-series-11-11-1215/"> Rutgers IIPL Algorithmic Justice Webinar, </a>with Julia Stoyanovich and Ellen Goodman!
										
										<p> Oct 2020: <a href="https://dataresponsibly.github.io/comics/vol1/mirror_en.pdf"> 'Mirror, Mirror' </a> and <a href="https://ai-ethics.github.io/decoded-reality/intro.html"> 'Decoded Reality' </a> have been accepted to the <a href="https://sites.google.com/view/resistance-ai-neurips-20/accepted-papers-and-media?authuser=0"> Resistance AI Workshop </a> at NeurIPS 2020!

										<p> Oct 2020: Started the <a href="https://github.com/acmi-lab/superheroes-deep-learning">"Superheroes of Deep Learning" </a>comic series, with Zack Lipton! Volume 1:<a href="https://www.approximatelycorrect.com/2020/10/26/superheroes-of-deep-learning-vol-1-machine-learning-yearning/"> 'Machine Learning Yearning'</a> is out now!


									</div>
								</div>
							</div>
						</div>
					</div>
				</div>
			</section>


			<section class="colorlib-research" data-section="research">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-6 col-md-offset-3 col-md-pull-3 animate-box" data-animate-effect="fadeInLeft">
							<span class="heading-meta">My Work</span>
							<h2 class="colorlib-heading animate-box">Research</h2>
						</div>
					</div>
					<div class="row">
						<div class="col-md-12 animate-box" data-animate-effect="fadeInLeft">
							<div class="fancy-collapse-panel">
								<div class="panel-group" id="accordion" role="tablist" aria-multiselectable="true">
									
									<div class="panel panel-default">
									    <div class="panel-heading" role="tab" id="headingOne">
									        <h4 class="panel-title">
									            <a data-toggle="collapse" data-parent="#accordion" href="#collapseOne" aria-expanded="true" aria-controls="collapseOne"> Philosophical and Normative Foundations of Algorithmic Fairness (Ongoing)
									            </a>
									        </h4>
									    </div>
									    <div id="collapseOne" class="panel-collapse collapse in" role="tabpanel" aria-labelledby="headingOne">
									         <div class="panel-body">
									            <div class="row">
										      		<p> The focus of my research is the question ``What does it mean for the outcomes of a data-driven system to be fair?'', and how do we encode this pluralistic concept into algorithms? There are several perspectives from which I am looking at this question.  The first is to ground statistical fairness definitions in strong normative foundations. This involves deeply engaging with literature in both fair-ML and moral philosophy to uncover the value judgements encoded in different mathematical criteria.  </p>

										      		<p> <strong> Equality of Opportunity (EO) </strong> is a political philosophy doctrine that objects to morally irrelevant factors affecting people's access to desirable positions in society. This is a rich space of ideas with different doctrines taking different views about which factors are morally relevant and irrelevant to decision-making, and about how to  correct for the effect of morally irrelevant factors. Further, different EO doctrines target different opportunities. For example, Rawls's doctrine focuses on developmental opportunities such as access to education. In-built into these doctrines is the nature of opportunity being allocated, and we can exploit this as one way to characterize context. A metric-to-doctrine mapping between fair-ML and political philosophy allows us to uncover the value judgements embedded into different statistical criteria, while the implicit doctrine-to-context mapping in EO doctrines presents us with a way to reason about the appropriateness of context-specific fairness criteria. 

										      		<p> <strong> Paper: </strong> <a href="https://dl.acm.org/doi/abs/10.1145/3551624.3555303"> Falaah Arif Khan, Eleni Manis and Julia Stoyanovich. Towards Substantive Conceptions of Algorithmic Fairness: Normative Guidance from Equal Opportunity Doctrines. ACM EAAMO 2022 </a> 

										      		<p> <strong> Comic book: </strong> <a href="https://dataresponsibly.github.io/comics/vol2/fairness_en.pdf"> Falaah Arif Khan, Eleni Manis and Julia Stoyanovich. “Fairness and Friends”. Data, Responsibly Comics, Volume 2 (2021) </a> </p>
										      		<p> <strong> Tutorial: </strong> <a href="https://www.youtube.com/watch?v=FUBVuOH5H9s&list=PLXA0IWa3BpHnYVwSLuvv1Jv1U1Pyhcymt"> Falaah Arif Khan, Eleni Manis and Julia Stoyanovich. Translation Tutorial: Fairness and Friends. ACM FAccT 2021 </a> </p>
										      	</div>
									         </div>
									    </div>
									</div>

									<div class="panel panel-default">
									    <div class="panel-heading" role="tab" id="headingTwo">
									        <h4 class="panel-title">
									            <a class="collapsed" data-toggle="collapse" data-parent="#accordion" href="#collapseFour" aria-expanded="false" aria-controls="collapseFour">Fairness and Arbitrariness in Decision-making (Ongoing)
									            </a>
									        </h4>
									    </div>
									    <div id="collapseFour" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingFour">
									        <div class="panel-body">
									            <div class="row">
									            	<p> The second focus of my research is to study how technical definitions of fairness trade off against other properties of ML systems such as stability. The intuition is that we should only care about whether the outcomes of a decision-making system are ``equally good'' for all people (fair), if the outcomes are good to begin with. Put differently, a system that is completely arbitrary, i.e., always returns a random guess, is trivially fair, and so fairness considerations need to be complemented with other important measures of predictive performance.

									            	<p> <strong> Validity </strong> is one such important property. We interrogated the validity of two real-world personality prediction AI used in hiring (called Crystal and HumanticAI, and advertised to be used by several Fortune 500 companies) by looking at the <strong> stability </strong> of the outputs they produce. One (among several) shocking findings of our paper was that these systems produce arbitrarily different scores for resumes that are identical in every other manner except file type (pdf vs rich text)! This finding illustrates that if outcomes are arbitrary then it is meaningless to think about fairness.

									            	<p> <strong> Paper:</strong> <a href="https://link.springer.com/article/10.1007/s10618-022-00861-0">Alene Kellogg Rhea, Kelsey Markey, Lauren D’Arinzo, Hilke Schellmann, Mona Sloane, Paul Squires, Falaah Arif Khan, and Julia Stoyanovich, ”An External Stability Audit Framework to Test the Validity of Personality Prediction in AI Hiring.” Data Mining and Knowledge Discovery, Special Issue on Bias and Fairness (2022)</a> </p> 

									            	<p> <strong> Github: </strong> <a href="https://github.com/DataResponsibly/hiring-stability-audit"> https://github.com/DataResponsibly/hiring-stability-audit </a> </p>


									            	<p>    </p>
									            	<p> From a conceptual standpoint, I'm also interested in the converse question: how do fairness interventions affect stability, i.e., <strong> does imposing fairness requirements make outcomes more (or less) arbitrary for certain social groups than for others? </strong> One way to think about this is through the lens of the elegant bias-variance decomposition of model error. I ask the question of whether this decomposition is different for different subgroups in the data.

									            	<p> <strong> Working Papers: </strong> <a href="https://doi.org/10.48550/arXiv.2302.04525"> Falaah Arif Khan, Denys Herasymuk, and Julia Stoyanovich. 2023. On Fairness and Stability: Is Estimator Variance a Friend or a Foe? arXiv (Feb. 2023) </a>

									            	<p> <a href="https://doi.org/10.48550/arXiv.2302.08704"> Falaah Arif Khan and Julia Stoyanovich. 2023. The Unbearable Weight of Massive Privilege: Revisiting Bias-Variance Trade-Offs in the Context of Fair Prediction. arXiv (Feb. 2023) </a>

									            </div>	
									        </div>
									    </div>
									</div>

									<div class="panel panel-default">
									    <div class="panel-heading" role="tab" id="headingThree">
									        <h4 class="panel-title">
									            <a class="collapsed" data-toggle="collapse" data-parent="#accordion" href="#collapseTwo" aria-expanded="false" aria-controls="collapseTwo">A Data-Centric, Lifecycle View of Fairness (Ongoing)
									            </a>
									        </h4>
									    </div>
									    <div id="collapseTwo" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingTwo">
									         <div class="panel-body">
									            <div class="row">
										      		<p>The third line of my work focuses on how different data interventions in the model lifecycle affect the fairness and arbitrariness of predictions. This work takes a data-centric view, framing each stage in the lifecycle as a data transformation and studying its bias-transforming or variance-transforming effects.

										      		<p> It is a widely held socio-technical belief that data from socially marginalized groups tends to be more noisy, and this can manifest downstream as model unfairness. We interrogated this claim, and the impact of automating the detection and cleaning of data errors on model fairness. Counter-intuitively,  we found that the incidence of automatically detected data errors ---  missing values, outliers and mislabels --- does not track protected group membership, and yet the downstream impact of automated cleaning of these errors is more likely to worsen fairness than to improve it! We posit that this could be due to one or both of the following reasons: data errors for marginalized groups may be harder to detect or they may be harder to repair, impacting model fairness downstream. This result demonstrates the need to adopt a <strong> lifecycle view of fairness </strong> (e.g., to look at the interactions between error detection and data cleaning on downstream performance). 

										      		<p> <strong> Paper: </strong> <a href="https://ssc.io/pdf/demodq.pdf"> Shubha Guha, Falaah Arif Khan, Julia Stoyanovich, and Sebastian Schelter. 2023. "Automated Data Cleaning Can Hurt Fairness in Machine Learning-based Decision Making". IEEE ICDE’23 </a> </p>
										     
										      	</div>
									         </div>
									    </div>
									</div>


									<div class="panel panel-default">
									    <div class="panel-heading" role="tab" id="headingFour">
									        <h4 class="panel-title">
									            <a class="collapsed" data-toggle="collapse" data-parent="#accordion" href="#collapseThree" aria-expanded="false" aria-controls="collapseThree">Behavior-based Authentication
									            </a>
									        </h4>
									    </div>
									    <div id="collapseThree" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingFour">
									         <div class="panel-body">
									            <div class="row">
										      		<p>In this work we investigated the efficacy of a novel “who I am/how I behave” authentication paradigm. Conventional authentication works on a “what I know” (username/password) or “what I have” (device) model. Our system would study the user’s behavior while typing his/her username and use the activity profile as the key against which access was granted. This eliminated the need for the user to remember a password or have access to a registered device. Conversely, even if a password is cracked or a device is stolen, the bad actor would not be able to penetrate the system because his behavior would intrinsically differ from that of the genuine user.</p>
										      		<p> <strong> Paper: </strong> <a href="https://www.researchgate.net/publication/330582894_Behavioral_Biometrics_and_Machine_Learning_to_Secure_Website_Logins_6th_International_Symposium_SSCC_2018_Bangalore_India_September_19-22_2018_Revised_Selected_Papers"> Falaah Arif Khan, Sajin Kunhambu and Kalyan G. Chakravarthy. (2019) Behavioral Biometrics and Machine Learning to Secure Website Logins. SSCC'18</a> </p>
										      		<p> <strong> US Patent: </strong> <a href="https://patentimages.storage.googleapis.com/49/0e/5e/484ead387672c6/US20200244639A1.pdf"> Falaah Arif Khan, Sajin Kunhambu and Kalyan G. Chakravarthy. Behavioral Biometrics and Machine Learning to secure Website Logins. US Patent 16/257650, filed January 25, 2019 </a> </p>
										      	</div>
									         </div>
									    </div>
									</div>
									
									<div class="panel panel-default">
									    <div class="panel-heading" role="tab" id="headingFive">
									        <h4 class="panel-title">
									            <a class="collapsed" data-toggle="collapse" data-parent="#accordion" href="#collapseSix" aria-expanded="false" aria-controls="collapseFour">Online-Learning for CAPTCHA Optimization
									            </a>
									        </h4>
									    </div>
									    <div id="collapseSix" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingFive">
									        <div class="panel-body">
									            <div class="row">
									            	<p>CAPTCHAs, short for Complete Automated Public Turing Tests to tell Computers and Humans Apart, have been around since 2003 as the simplest human-user identification test. They can be understood as Reverse Turing Tests because in solving a CAPTCHA challenge it is a human subject that is appearing to prove his/her human-ness to a computer program. </p>
									            	<p> Over the years we have seen CAPTCHA challenges evolve from being a string of characters for the user to decipher, to be an image selection challenge, to being as simple as ticking a checkbox. As each new CAPTCHA scheme hits the market, it is inevitably followed with research on new techniques to break these challenges. Engineers must then go back to the drawing board and design a new and more secure CAPTCHA scheme, which, upon deployment and subsequent use, is again, inadvertently subject to adversarial scrutiny. This arduous cycle of designing, breaking and then redesigning to strengthen against subsequent breaking, has become the de-facto lifecycle of a secure CAPTCHA scheme. This beckons the question; Are our CAPTCHAs truly “Completely Automated”? Is the labor involved in designing each new secure scheme outweighed by the speed with which a suitable adversary can be designed? Is the fantasy of creating a truly automated reverse Turing test dead? </p>
									            	<p> Reminding ourselves of why we count CAPTCHAs as such an essential tool in our security toolbox, we characterize CAPTCHAs in a robustness-user experience-feasibility trichotomy. With such a characterization, we introduce a novel framework that leverages Adversarial Learning and Human-in-the-Loop Bayesian Inference to design CAPTCHAs schemes that are truly automated. We apply our framework to character CAPTCHAs and show that it does in fact generate a scheme that steadily moves closer to our design objectives of maximizing robustness while maintaining user experience and minimizing allocated resources, without requiring manual redesigning. </p>
									            	<p> <strong> US Patent: </strong> <a href="https://patentimages.storage.googleapis.com/ed/af/96/08411a299e082e/US11386193.pdf"> Falaah Arif Khan and Hari Surender Sharma. Framework to Design Completely Automated Reverse Turing Tests. US Patent 16/828520, filed March 24, 2020 and US Patent (Provisional) 62/979500, filed February 21, 2020  </a> </p>
									        	</div>
									        </div>
									    </div>
									</div>

								</div>
							</div>
						</div>
					</div>
				</div>
			</section>

			

			<section class="colorlib-gallery" data-section="gallery">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-12">
							<div class="row row-bottom-padded-sm animate-box" data-animate-effect="fadeInLeft">
								<div class="col-md-12">
									<div class="about-desc">
										<span class="heading-meta">Art</span>
						    			<h2 class="colorlib-heading">Machine Learnist Comics</h2>
						    			<a href="https://www.patreon.com/machinelearnist"><img src="images/cover.png" class="img-responsive" alt="Two humans on either side push two spheres towards each other. The intersection of the two spheres, which looks like a classic 2 class Venn diagram has the words 'ML Comics' in it. The person on the left is drawn in pixel art, whereas the person on the right is drawn with a watercolor effect."></a>
						    			<p></p>
						    			<h5> Follow on <a href='https://twitter.com/MachineLearnist'> Twitter </a>, <a href='https://www.facebook.com/TheMachineLearnist'> Facebook, </a> <a href='https://www.instagram.com/themachinelearnist/'> Instagram </a> and support on <a href='https://www.patreon.com/machinelearnist'> Patreon! </a> </h5>
						    			
						    			
						    			<h2 class="colorlib-heading">Latest Volumes!</h2>

						    			<a href="https://www.approximatelycorrect.com/2021/08/10/superheroes-of-deep-learning-vol-2-machine-learning-for-healthcare/"><img src="images/DLHeroes2.png" class="img-responsive" width="600" height="700" alt="DL Heroes 2 cover"></a>
						    			<p></p>
						    			<h5> Falaah Arif Khan and Zachary C. Lipton. “Superheroes of Deep Learning Volume 2: Machine Learning for Healthcare” (August, 2021)</h5>
						    			<p></p>
						    			<p></p>

						    			<a href="http://bit.ly/we-are-ai_comics_vol5_en">
						    			<img src="images/5-cover.png" class="img-responsive" width="600" height="700" alt="We Are AI Cover art."></a>
						    			<p></p>
						    			<h5> Julia Stoyanovich and Falaah Arif Khan. “We are AI”. We are AI Comics, Volume 5 (June, 2021)</h5>
						    			<p></p>
						    			<p></p>

						    			<a href="http://bit.ly/we-are-ai_comics_vol4_en">
						    			<img src="images/4-cover.png" class="img-responsive" width="600" height="700" alt="We Are AI Cover art."></a>
						    			<p></p>
						    			<h5> Julia Stoyanovich and Falaah Arif Khan. “All about that Bias”. We are AI Comics, Volume 4 (June, 2021)</h5>
						    			<p></p>
						    			<p></p>

						    			<a href="http://bit.ly/we-are-ai_comics_vol3_en">
						    			<img src="images/3-cover.png" class="img-responsive" width="600" height="700" alt="We Are AI Cover art."></a>
						    			<p></p>
						    			<h5> Julia Stoyanovich, Mona Sloane and Falaah Arif Khan. “Who lives, who dies, who decides?”. We are AI Comics, Volume 3 (May, 2021)</h5>
						    			<p></p>
						    			<p></p>
						    			
						    			<a href="http://bit.ly/we-are-ai_comics_vol2_en">
						    			<img src="images/2-cover.png" class="img-responsive" width="600" height="700" alt="We Are AI Cover art."></a>
						    			<p></p>
						    			<h5> Julia Stoyanovich and Falaah Arif Khan. “Learning from Data”. We are AI Comics, Volume 2 (May, 2021)</h5>
						    			<p></p>
						    			<p></p>

						    			<a href="http://bit.ly/we-are-aicomicsvol1">
						    			<img src="images/1-cover.png" class="img-responsive" width="600" height="700" alt="We Are AI Cover art."></a>
						    			<p></p>
						    			<h5> Julia Stoyanovich and Falaah Arif Khan. “What is AI?”. We are AI Comics, Volume 1 (May, 2021)</h5>
						    			<p></p>
						    			<p></p>

						    			<a href="https://dataresponsibly.github.io/comics/vol2/fairness_en.pdf">
						    			<img src="images/Fairness_Cover.png" class="img-responsive" width="600" height="700" alt="Artistic depiction of Lady Justice using line and abstract art."></a>
						    			<p></p>
						    			<h5> Falaah Arif Khan, Eleni Manis and Julia Stoyanovich “Fairness and Friends”. Data, Responsibly Comics, Volume 2 (Feb, 2021)</h5>
						    			<p></p>
						    			<p></p>

						    			<a href="https://www.approximatelycorrect.com/2020/10/26/superheroes-of-deep-learning-vol-1-machine-learning-yearning/"><img src="images/DLHeroes1.PNG" class="img-responsive" width="600" height="700" alt="David silver, Andrew ng and Fei Fei li in their superhero form as Q-Silver, MOOC and Benchmark, respectively. Q-Silver is in the middle and is lunging towards the screen. MOOC is to the left and is jumping up into the screen with his arms outstretched and muscles in full display. Benchmark is lunging in cat-like positive to the right. Machine Learning Yearning is written above them."></a>
						    			<p></p>
						    			<h5> Falaah Arif Khan and Zachary C. Lipton. “Superheroes of Deep Learning Volume 1: Machine Learning Yearning” (Oct, 2020) </h5>
						    			<p></p>
						    			<p></p>

						    			<a href="https://dataresponsibly.github.io/comics/"><img src="images/Mirror_Mirror_Cover.png" class="img-responsive" width="600" height="700" alt="Digital painting of a woman, wearing dark sunglasses. In the left pane of the sunglass is the recreation of the cover of the movie Titanic, where Rose is replaced by an android. In the right pane is the painting of the iconic fight scene from Rocky, with the opponent replaced as an Android. The space surrounding the woman has line and abstract art in the shape of flames."></a>
						    			<p></p>
						    			<h5> Falaah Arif Khan and Julia Stoyanovich. “Mirror, Mirror”. Data, Responsibly Comics, Volume 1 (Sept, 2020)</h5>
						    			<p></p>
						    			<p></p>

						    			<a href="https://interactiveaimag.org/columns/articles/comic/meet-ai-comic-vol-1-ed-2/"><img src="images/vol1_cover.png" class="img-responsive" width="600" height="700" alt="Recreation of the last scene of fight club, where the Narrator and Marla stand holding handing as buildings explode around them. In this reimagining of that iconic scene, the narrator is replaced by a humanoid/robot and has the words AI on it's coat"></a>
						    			<p></p>
						    			<h5> Falaah Arif Khan. "Meet AI" (June, 2020). In AAAI Interactive Magazine </h5>						    			
						    			<p></p>


									</div>
								</div>
							</div>
						</div>
					</div>
					<div class="row">
						<div class="col-md-12">
							<div class="row row-bottom-padded-sm animate-box" data-animate-effect="fadeInLeft">
								<div class="col-md-12">
									<div class="about-desc">
										<h2 class="colorlib-heading">Traditional Art</h2>
										<h4> Go to my <a href="https://www.instagram.com/thefaladox/"> Instagram page </a> to see my art! </h4>
						    			<a href="https://www.instagram.com/thefaladox/"><img src="images/collage.png" class="img-responsive" alt="Collage of different artworks in various styles ranging from Polygon art to line art, watercolor, soft pastels, pencil and pen sketch"></a>
						    		</div>
						    	</div>
						    </div>
						</div>
					</div>
				</div>
			</section>



			<section class="colorlib-blog" data-section="blog">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-6 col-md-offset-3 col-md-pull-3 animate-box" data-animate-effect="fadeInLeft">
							<span class="heading-meta">Stuff</span>
							<h2 class="colorlib-heading">Articles, Talks and More!</h2>
						</div>
					</div>

					<div class="row">

						<div class="col-md-4 col-sm-6 animate-box" data-animate-effect="fadeInLeft">
							<div class="blog-entry">
								<a href="https://hayatlife.com/2021/03/17/falaah-arif-khan-ai-comic-interview/" class="blog-img"><img src="images/hayat.PNG" class="img-responsive"></a>
								<div class="desc">
									<span><small>March 17, 2021</small> | <small> Interview </small></span>
									<h3><a href="https://hayatlife.com/2021/03/17/falaah-arif-khan-ai-comic-interview/">Interview with Hayat Life</a></h3>
									<p>I sat down with the folks at Hayat Life to talk about my ML comics - what inspired me to start making them, where I envision them going, and what to expect next! </p>
								</div>
							</div>
						</div>

						<div class="col-md-4 col-sm-6 animate-box" data-animate-effect="fadeInLeft">
							<div class="blog-entry">
								<a href="https://riipl.rutgers.edu/2020/11/10/riipl-algorithmic-justice-webinar-series-11-11-1215/" class="blog-img"><img src="images/riipl.PNG" class="img-responsive"></a>
								<div class="desc">
									<span><small>November 11, 2020</small> | <small> Interview </small></span>
									<h3><a href="https://www.govtech.com/opinion/Comic-Book-Bridges-Gap-Around-Education-in-AI-Ethics.html">RIIPL Algorithmic Justice Webinar Series</a></h3>
									<p>The amazing Julia Stoyanovich and I sat down with Ellen Goodman, from the Rutgers Institute for Information Policy and Law, to discuss the comedic treatment of AI bias, normativity and exclusion, in the context of our 'Data, Responsibly' Comic books! </p>
								</div>
							</div>
						</div>

						<div class="col-md-4 col-sm-6 animate-box" data-animate-effect="fadeInLeft">
							<div class="blog-entry">
								<a href="https://ai-ethics.github.io/decoded-reality/intro.html" class="blog-img"><img src="images/decoded_reality.png" class="img-responsive"></a>
								<div class="desc">
									<span><small>November, 2020</small> | <small> Visual Essay </small></span>
									<h3><a href="https://ai-ethics.github.io/decoded-reality/intro.html">Decoded Reality</a></h3>
									<p>Decoded Reality is a visual essay on the power dynamics that shape the design, development and deployment of ML systems. We present artistic interpretations of how algorithmic interventions manifest in society in the hope of provoking the designers of these systems to think critically about the socio-political underpinnings of each step of the engineering process.</p>
								</div>
							</div>
						</div>
					</div>


					<div class = "row">
						<div class="col-md-4 col-sm-6 animate-box" data-animate-effect="fadeInLeft">
							<div class="blog-entry">
								<a href="https://www.govtech.com/opinion/Comic-Book-Bridges-Gap-Around-Education-in-AI-Ethics.html" class="blog-img"><img src="images/datagov.jpg" class="img-responsive"></a>
								<div class="desc">
									<span><small>September 30, 2020</small> | <small> Interview </small></span>
									<h3><a href="https://www.govtech.com/opinion/Comic-Book-Bridges-Gap-Around-Education-in-AI-Ethics.html">MetroLab "Innovation of the Month" Feature</a></h3>
									<p>"Mirror, Mirror" was featured as the MetroLab Network+ Government Technology "Innovation of the Month". In this interview we discuss the origins of the project, our creative process and the future of Data, Responsibly Comics! </p>
								</div>
							</div>
						</div>

						<div class="col-md-4 col-sm-6 animate-box" data-animate-effect="fadeInLeft">
							<div class="blog-entry">
							<a href="http://approximatelycorrect.com/2020/09/15/hope-returns-to-the-machine-learning-universe/" class="blog-img"><img src="images/Teaser.png" class="img-responsive"></a>
								<div class="desc">
									<span><small>September 15, 2020</small> | <small> Article (Satire) </small> </span>
									<h3><a href="http://approximatelycorrect.com/2020/09/15/hope-returns-to-the-machine-learning-universe/">Hope Returns to the Machine Learning Universe</a></h3>
									<p>According to witnesses, Earth's been visited by the *Superheroes of Deep Learning*. What do they want? What powers do they possess? Will they fight for good or for evil? Read to learn more!.</p>
								</div>	
							</div>
						</div>

						<div class="col-md-4 col-sm-6 animate-box" data-animate-effect="fadeInLeft">
							<div class="blog-entry">
							<a href="https://aihub.org/2020/06/11/interview-with-falaah-arif-khan-talking-security-comics-and-demystifying-the-hype-surrounding-ai/" class="blog-img"><img src="images/comic.png" class="img-responsive"></a>
								<div class="desc">
									<span><small>June 11th, 2020 </small> | <small> Interview </small> </span>
									<h3><a href="https://aihub.org/2020/06/11/interview-with-falaah-arif-khan-talking-security-comics-and-demystifying-the-hype-surrounding-ai/">Interview with AI Hub</a></h3>
									<p>I sat down with the folks at AIHub to chat about my research and art. We talk (meta-)security, scientific comics and demystifying the hype around AI. </p>
								</div>	
							</div>
						</div>				
					</div>


					<div class = "row">
						<div class="col-md-4 col-sm-6 animate-box" data-animate-effect="fadeInLeft">
							<div class="blog-entry">
							<a href="https://thefaladox.wordpress.com/2020/01/04/deep-learning-perspectives-from-death-note-another-approximately-inimitable-exegesis/" class="blog-img"><img src="images/Death_Note.png" class="img-responsive"></a>
								<div class="desc">
									<span><small>January 4, 2020 </small> | <small> Article </small> </span>
									<h3><a href="https://thefaladox.wordpress.com/2020/01/04/deep-learning-perspectives-from-death-note-another-approximately-inimitable-exegesis/">Deep Learning Perspectives from Death Note: Another Approximately Inimitable Exegesis</a></h3>
									<p>Masked under a binge-worthy anime lies an adept critique of the ongoing deep learning craze in the industry. Here’s my commentary on the technical symbols in Death Note.</p>
								</div>	
							</div>
						</div>

						<div class="col-md-4 col-sm-6 animate-box" data-animate-effect="fadeInLeft">
							<div class="blog-entry">
							<a href="https://thefaladox.wordpress.com/2020/07/11/what-is-meta-security/" class="blog-img"><img src="images/metasecurity.png" class="img-responsive"></a>
								<div class="desc">
									<span><small>July 11th, 2020 </small> | <small> Article (Satire) </small> </span>
									<h3><a href="https://thefaladox.wordpress.com/2020/07/11/what-is-meta-security/">What is Meta-Security?</a></h3>
									<p>In this seminal essay, I explain the hottest up and coming sub-field of Machine Learning - Meta-Security!</p>
								</div>	
							</div>
						</div>		
					</div>
				</div>
			</section>


			<section class="colorlib-contact" data-section="contact">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-12">
							<div class="row row-bottom-padded-sm animate-box" data-animate-effect="fadeInLeft">
								<div class="col-md-12">
									<div class="about-desc">
										<span class="heading-meta">Get in Touch</span>
										<h2 class="colorlib-heading">Contact</h2>
										<p>Get in touch if you want to collaborate on an interesting project, want to commission some custom artwork, or simply want to discuss something wonderfully esoteric!</p>
									</div>
								</div>
							</div>
						</div>
					</div>
					<div class="row">
						<div class="col-md-5">
							<div class="colorlib-feature colorlib-feature-sm animate-box" data-animate-effect="fadeInLeft">
								<div class="colorlib-text">
									<p><a href="mailto:fa2161@nyu.edu">Email</a></p>
									<p><a href="https://twitter.com/FalaahArifKhan">Twitter</a></p>
									<p><a href="https://scholar.google.com/citations?hl=en&user=53O3iRgAAAAJ&view_op=list_works&sortby=pubdate">Google Scholar</a></p>
									<p><a href="https://www.linkedin.com/in/falaah-arif-khan-b99058154/">LinkedIn</a></p>
								</div>
							</div>
						</div>
					</div>
				</div>
			</section>

		</div><!-- end:colorlib-main -->
	</div><!-- end:container-wrap -->
	</div><!-- end:colorlib-page -->

	<!-- jQuery -->
	<script src="js/jquery.min.js"></script>
	<!-- jQuery Easing -->
	<script src="js/jquery.easing.1.3.js"></script>
	<!-- Bootstrap -->
	<script src="js/bootstrap.min.js"></script>
	<!-- Waypoints -->
	<script src="js/jquery.waypoints.min.js"></script>
	<!-- Flexslider -->
	<script src="js/jquery.flexslider-min.js"></script>
	<!-- Owl carousel -->
	<script src="js/owl.carousel.min.js"></script>
	<!-- Counters -->
	<script src="js/jquery.countTo.js"></script>
	
	
	<!-- MAIN JS -->
	<script src="js/main.js"></script>

	</body>
</html>

