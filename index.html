<!DOCTYPE HTML>
<html>
	<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Falaah Arif Khan</title>
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="" />
	<meta name="keywords" content="" />
	<meta name="author" content="" />

  <!-- Facebook and Twitter integration -->
	<meta property="og:title" content=""/>
	<meta property="og:image" content=""/>
	<meta property="og:url" content=""/>
	<meta property="og:site_name" content=""/>
	<meta property="og:description" content=""/>
	<meta name="twitter:title" content="" />
	<meta name="twitter:image" content="" />
	<meta name="twitter:url" content="" />
	<meta name="twitter:card" content="" />

	<!-- Place favicon.ico and apple-touch-icon.png in the root directory -->
	<link rel="shortcut icon" href="favicon.ico">

	<link href="https://fonts.googleapis.com/css?family=Quicksand:300,400,500,700" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Playfair+Display:400,400i,700" rel="stylesheet">
	
	<!-- Animate.css -->
	<link rel="stylesheet" href="css/animate.css">
	<!-- Icomoon Icon Fonts-->
	<link rel="stylesheet" href="css/icomoon.css">
	<!-- Bootstrap  -->
	<link rel="stylesheet" href="css/bootstrap.css">
	<!-- Flexslider  -->
	<link rel="stylesheet" href="css/flexslider.css">
	<!-- Flaticons  -->
	<link rel="stylesheet" href="fonts/flaticon/font/flaticon.css">
	<!-- Owl Carousel -->
	<link rel="stylesheet" href="css/owl.carousel.min.css">
	<link rel="stylesheet" href="css/owl.theme.default.min.css">
	<!-- Theme style  -->
	<link rel="stylesheet" href="css/style.css">

	<!-- Modernizr JS -->
	<script src="js/modernizr-2.6.2.min.js"></script>
	<!-- FOR IE9 below -->
	<!--[if lt IE 9]>
	<script src="js/respond.min.js"></script>
	<![endif]-->

	</head>
	<body>
	<div id="colorlib-page">
		<div class="container-wrap">
		<a href="#" class="js-colorlib-nav-toggle colorlib-nav-toggle" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar"><i></i></a>
		<aside id="colorlib-aside" role="complementary" class="border js-fullheight">
			<div class="text-center">
				<div class="author-img" style="background-image: url(images/about.png);"></div>
				<h1 id="colorlib-logo"><a href="index.html">Falaah Arif Khan</a></h1>
				<h6>  I do Science and create Art </h6>				
			</div>
			<nav id="colorlib-main-menu" role="navigation" class="navbar">
				<div id="navbar" class="collapse">
					<ul>
						<li class="active"><a href="#" data-nav-section="about">About</a></li>
						<li><a href="#" data-nav-section="news">News</a></li>
						<li><a href="#" data-nav-section="research">Research</a></li>
						<li><a href="#" data-nav-section="gallery">ML Comics</a></li>
						<li><a href="#" data-nav-section="blog">Stuff</a></li>
						<li><a href="#" data-nav-section="contact">Contact</a></li>
					</ul>
				</div>
			</nav>

			<div class="colorlib-footer">
				<p><small>&copy; <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
Copyright &copy;<script>document.write(new Date().getFullYear());</script> All rights reserved | This template is made with <i class="icon-heart" aria-hidden="true"></i> by <a href="https://colorlib.com" target="_blank">Colorlib</a>
<!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. --> 
			</div>

		</aside>

		<div id="colorlib-main">
			<section class="colorlib-about" data-section="about">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-12">
							<div class="row row-bottom-padded-sm animate-box" data-animate-effect="fadeInLeft">
								<div class="col-md-12">
									<div class="about-desc">
										<span class="heading-meta">About</span>
										<h2 class="colorlib-heading">Who Am I?</h2>
										<p><strong>Hi! I'm Falaah.</strong> I'm a Engineer/Scientist by training and an Artist by nature, broadly interested in reliable and "responsible" AI. Towards this end, I conduct fundamental research on "fairness" in machine learning, responsible data science and robust machine learning, and create scientific comics (and other artwork) to disseminate the nuances of this work in a way that is more accessible to a variety of (technical and non-technical) audiences.

										I'm currently a second-year PhD student at NYU's <a href="https://cds.nyu.edu"> Center for Data Science</a>, and an Artist-in-Residence at the <a href="http://airesponsibly.com/"> Center for Responsible AI (R/AI) </a>. I'm extremely lucky to get to do two things I absolutely love to do: fundamental research and creating scientific comics!
 
										<p>At NYU, I'm advised by the inimitable <a href="http://stoyanovich.org/">Prof Julia Stoyanovich</a>. Broadly, we work on the societal impacts of AI, and the normative and technical dimensions of algorithmic fairness. Check out the "Research" section of this page for more details about ongoing research. Excitingly, Julia and I also create several comic series at NYU R/AI: the 'Data, Responsibly' Comic series, targeted at a semi-technical audiences, and the 'We are AI' comics, created for the general public. We recently did a deep dive on the accessibility of the 'We are AI' comics through a series of roundtables with accessibility experts, and are currently working on a brand new comic series about AI for a broad, general audience. Stay tuned for details on this exciting new series! 
										
										<p>I also (now less frequently) create the <a href="https://github.com/acmi-lab/superheroes-deep-learning">'Superheroes of Deep Learning'</a> comics with <a href="http://zacklipton.com/">Prof Zack Lipton</a>, which documents the thrilling tales and heroic feats of ML's larger-than-life champions.
										
										Before starting my PhD, I did an Artist Residency at the Montreal AI Ethics Institute. My visual essay, <a href="https://ai-ethics.github.io/decoded-reality/intro.html"> 'Decoded Reality'</a>, is an artistic exploration of the power dynamics that shape the design, development and deployment of ML systems. We present visual interpretations of how algorithmic interventions manifest in society, with the hope of provoking the designers of these systems to think critically about the socio-political underpinnings of each step of the engineering process.

										<p>Previously, I worked as a Research Engineer at Dell EMC, Bangalore where I designed and built data-driven models for Identity and Access Management (IAM). My research focused on behavior-based Authentication, online learning for CAPTCHA design and (Graph) Signal Processing for Dynamic Threat Modelling. For more details on these projects, check out the "Research" section. </p>
										
										<p>My work in the industry showed me firsthand the pressing challenges of building 'production-ready' models. Contrary to the media narrative around AI, this technology is far from being 'sophisticated' --- we are yet to have figured out how to build models that are robust, reliable and designed to thrive in the wild. These challenges have informed my interest to explore the foundations of generalization, robustness and fairness. One interesting way to explore these questions is by critically assessing how AI impacts, and is in turn impacted by, the underlying social setting in which it was formulated. </p>
										
										<p> <a href="documents/CV.pdf">Curriculum Vitae</a> &emsp; <a href="https://scholar.google.com/citations?hl=en&user=53O3iRgAAAAJ&view_op=list_works&sortby=pubdate">Google Scholar</a></p>
									</div>
								</div>
							</div>
						</div>
					</div>
				</div>
			</section>

			<section class="colorlib-about" data-section="news">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-12">
							<div class="row row-bottom-padded-sm animate-box" data-animate-effect="fadeInLeft">
								<div class="col-md-12">
									<div class="news-desc">
										<span class="heading-meta">News</span>
										<h2 class="colorlib-heading">News</h2>

										<p> October 2022: Our work on <a href="https://eaamo.org/papers/khan-19.pdf"> Fairness as Equal Opportunity </a> has been accepted to <a href="https://eaamo.org/#home"> ACM EAAMO'22 </a> for an Oral presentation!

										<p> Aug 2022: Our paper on <a href="https://link.springer.com/article/10.1007/s10618-022-00861-0">Stability Auditing of Personality Prediction AI</a> was accepted to the Special Edition on Fairness and Bias of the Data Mining and Knowledge Discovery Journal! 

										<p> Summer 2022: We (<a href="https://airesponsibly.net">R/AI</a>) are ran a 6-week summer research program in collaboration with the Ukranian Catholic University! #ScienceForUkraine. Check out the final project showcase <a href="https://airesponsibly.net/2022/09/26/nyu-r-ai-summer-research-program-2022/">here</a>!

										<p> July 2022: Giving D&I talks at IEEE MDM 2022 <a href="https://www.youtube.com/embed/ZWdgiF-940A"> (video) </a> and ACM DEBS 2022 <a href="https://www.youtube.com/watch?v=c8jtDqCWYjU"> (video) </a>!

										<p> August 2021: New Superheroes of Deep Learning comic <a href="https://www.approximatelycorrect.com/2021/08/10/superheroes-of-deep-learning-vol-2-machine-learning-for-healthcare/">'Machine Learning for Healthcare'</a> is out now!

										<p> May-June 2021:  We just released a brand new, public-facing comic series, titled <a href="https://dataresponsibly.github.io/we-are-ai/comics/">'We are AI'</a>! It's a 5-volume primer on AI, blending the social, the legal and the technical, for anyone and everyone, and it accompanies <a href="https://airesponsibly.com/"> R/AI</a>'s new <a href="https://dataresponsibly.github.io/we-are-ai/">public education course</a> of the same name.

										<p> April 2021: Giving an invited talk titled "It's funny because it's true: confronting ML catechisms" at the <a href="https://rethinkingmlpapers.github.io/">'Rethinking ML Papers'</a> Workshop @ICLR 2021! Video recording <a href="https://slideslive.com/38956531">here </a>. (My talk starts at ~2:48:00)

										<p> April 2021: 'Fairness and Friends' has been accepted as an exhibit to the <a href="https://rethinkingmlpapers.github.io/papers/">'Rethinking ML Papers'</a> Workshop @ICLR 2021! Video explainer <a href="https://www.youtube.com/watch?v=aRpB57fd4YU"> here. </a> 

										<p> March 2021: Hosting <a href="https://schedule.mozillafestival.org/session/NWWNHA-1"> 'Decoded Reality' </a> - a collaborative, community brainstorm session about the role of Power in the creation of Responsible AI, at <a href="https://www.mozillafestival.org/en/"> MozFest 2021 </a>, based on <a href="https://ai-ethics.github.io/decoded-reality/intro.html"> my visual essay </a> of the same name!
										
										<p> March 2021: Presenting <a href="https://facctconference.org/2021/acceptedtuts.html#Friends"> 'Fairness and Friends' </a> - a translation tutorial that bridges scholarship from political philosophy and fair-ML - with Julia Stoyanovich and Eleni Manis, at ACM FAccT 2021! Recording is available <a href="https://www.youtube.com/watch?v=GiI6-tVYFoA"> here. </a> 
										
										<p> Feb 2021: Data, Responsibly Comics Vol 2: <a href="https://dataresponsibly.github.io/comics/vol2/fairness_en.pdf">'Fairness and Friends'</a> is out now!
										
										<p> Jan 2021: RDS Comics, Vol 1: 'Mirror, Mirror' has been translated into <a href="https://dataresponsibly.github.io/comics/vol1/mirror_fr.pdf"> French!!! </a>
 
										<p> Dec 2020: Facilitating the MAIEI x RAIN-Africa collaboration <a href="https://www.eventbrite.ca/e/perspectives-on-the-future-of-responsible-ai-in-africa-tickets-130080848319#"> 'Perspectives on the future of Responsible AI in Africa' </a> workshop. </a>
										
										<p> Dec 2020: The <a href="https://dataresponsibly.github.io/comics/vol1/mirror_fr.pdf"> Spanish edition </a> of RDS Comics, Volume 1: 'Mirror, Mirror' is out now!!!
										
										<p> Nov 2020: Facilitating the <a href="https://www.eventbrite.com/e/ai4good-x-maiei-privacy-in-artificial-intelligence-tickets-127902197917?utm-medium=discovery&utm-campaign=social&utm-content=attendeeshare&aff=escb&utm-source=cp&utm-term=listing"> 'Privacy in AI' Workshop </a>, by MAIEI and the AI4Good Lab
										
										<p> Nov 2020: Excited to be speaking at the <a href="https://www.facebook.com/events/1123723731398684/?active_tab=about"> 'Ethics in AI Panel' </a> by the McGill AI Society
										
										<p> Nov 2020: Giving an invited talk on 'Ethics in AI', based off of <a href="https://ai-ethics.github.io/decoded-reality/intro.html"> Decoded Reality</a>, at the <a href="https://techaidemontreal.org/2020-ai-conference-and-hackathon"> TechAide Montreal AI4Good Conference + Hackathon </a>

										<p> Nov 2020: Speaking about our 'Data, Responsibly' Comic books at the <a href="https://riipl.rutgers.edu/2020/11/10/riipl-algorithmic-justice-webinar-series-11-11-1215/"> Rutgers IIPL Algorithmic Justice Webinar, </a>with Julia Stoyanovich and Ellen Goodman!
										
										<p> Oct 2020: <a href="https://dataresponsibly.github.io/comics/vol1/mirror_en.pdf"> 'Mirror, Mirror' </a> and <a href="https://ai-ethics.github.io/decoded-reality/intro.html"> 'Decoded Reality' </a> have been accepted to the <a href="https://sites.google.com/view/resistance-ai-neurips-20/accepted-papers-and-media?authuser=0"> Resistance AI Workshop </a> at NeurIPS 2020!

										<p> Oct 2020: Started the <a href="https://github.com/acmi-lab/superheroes-deep-learning">"Superheroes of Deep Learning" </a>comic series, with Zack Lipton! Volume 1:<a href="https://www.approximatelycorrect.com/2020/10/26/superheroes-of-deep-learning-vol-1-machine-learning-yearning/"> 'Machine Learning Yearning'</a> is out now!


									</div>
								</div>
							</div>
						</div>
					</div>
				</div>
			</section>


			<section class="colorlib-research" data-section="research">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-6 col-md-offset-3 col-md-pull-3 animate-box" data-animate-effect="fadeInLeft">
							<span class="heading-meta">My Work</span>
							<h2 class="colorlib-heading animate-box">Research</h2>
						</div>
					</div>
					<div class="row">
						<div class="col-md-12 animate-box" data-animate-effect="fadeInLeft">
							<div class="fancy-collapse-panel">
								<div class="panel-group" id="accordion" role="tablist" aria-multiselectable="true">
									
									<div class="panel panel-default">
									    <div class="panel-heading" role="tab" id="headingOne">
									        <h4 class="panel-title">
									            <a data-toggle="collapse" data-parent="#accordion" href="#collapseOne" aria-expanded="true" aria-controls="collapseOne"> Fairness as Equal Opportunity
									            </a>
									        </h4>
									    </div>
									    <div id="collapseOne" class="panel-collapse collapse in" role="tabpanel" aria-labelledby="headingOne">
									         <div class="panel-body">
									            <div class="row">
										      		<p> Recent interest in codifying fairness in Automated Decision Systems (ADS) has resulted in a wide range of formulations of what it means for an algorithmic system to be fair. Most of these propositions are inspired by, but inadequately grounded in, political philosophy scholarship. This work aims to correct that deficit: we use Equal Oppportunity (EO) doctrines from political philosophy to make explicit the normative judgements embedded in different conceptions of algorithmic fairness. We contrast formal EO approaches that narrowly focus on fair contests at discrete decision points, with substantive EO doctrines that look at people's fair life chances more holistically over the course of a lifetime. We use this taxonomy to provide a moral interpretation of the impossibility results as the incompatibility between different conceptions of a fair contest -- foward-looking versus backward-looking -- when people do not have fair life chances. We use this result to motivate substantive conceptions of algorithmic fairness and outline two modern interpretations of classic substantive EO doctrines based on the luck-egalitarian doctrine of EO, and Rawls's principle of fair equality of opportunity. </p>
										      		<p> <strong> Paper: </strong> <a href="https://eaamo.org/papers/khan-19.pdf"> Falaah Arif Khan, Eleni Manis and Julia Stoyanovich. Towards Substantive Conceptions of Algorithmic Fairness: Normative Guidance from Equal Opportunity Doctrines. ACM EAAMO 2022 </a> </p> 
										      		<p> <strong> Comic book: </strong> <a href="https://dataresponsibly.github.io/comics/vol2/fairness_en.pdf"> Falaah Arif Khan, Eleni Manis and Julia Stoyanovich. “Fairness and Friends”. Data, Responsibly Comics, Volume 2 (2021) </a> </p>
										      		<p> <strong> Tutorial: </strong> <a href="https://www.youtube.com/watch?v=FUBVuOH5H9s&list=PLXA0IWa3BpHnYVwSLuvv1Jv1U1Pyhcymt"> Falaah Arif Khan, Eleni Manis and Julia Stoyanovich. Translation Tutorial: Fairness and Friends. ACM FAccT 2021 </a> </p>
										      	</div>
									         </div>
									    </div>
									</div>

									<div class="panel panel-default">
									    <div class="panel-heading" role="tab" id="headingFour">
									        <h4 class="panel-title">
									            <a class="collapsed" data-toggle="collapse" data-parent="#accordion" href="#collapseFour" aria-expanded="false" aria-controls="collapseFour">Stability of Data Science Pipelines 
									            </a>
									        </h4>
									    </div>
									    <div id="collapseFour" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingFour">
									        <div class="panel-body">
									            <div class="row">
									            	<p> Stability is the property of an algorithm whereby small changes in the input lead to small changes in the output.  Stability is a necessary (although not a sufficient) condition for reliability and trustworthiness of an algorithmic system: if small changes in the input lead to large changes in the output, this may be an indication that the model overfits the data or that it was deliberately tuned -- manipulated -- to produce a specific output for the given input. In this work, we make two observations: The first is that training data is itself a product of complex multi-step data manipulation pipelines, in which data is integrated, cleaned and otherwise pre-processed (e.g., queried to select subsets, or augmented to improve coverage of specific regions).  The second observation is that data quality may be different (lower) when it corresponds to members of historically disadvantaged groups.  Based on the second observation, we hypothesize that, because some data subsets are dirtier, both predictive accuracy and stability of models on these slices will be particularly sensitive to the choice of data cleaning methods and other kinds of pre-processing.  This is an example of technical bias, the type of bias that arises due to the characteristics of the technical system, can amplify pre-existing bias (also known as “bias in the data”), and leads to discriminatory outcomes. </p>
									            	<p> We are currently working on interrogating the impact of technical choices during data pre-processing (such as the choice of a missing value imputation method) on stability of the resulting models, and to quantify disparities in stability between slices that correspond to different demographic groups. </p>
									            	<p> A parallel line of work is to create an open-source software framework to audit the stability of any data science pipeline. Towards this end, we have a Python package which we initially developed to audit the stability of AI used for personality prediction in hiring.

									            	<p> <strong>Journal Paper:</strong> <a href="https://link.springer.com/article/10.1007/s10618-022-00861-0">Alene Kellogg Rhea, Kelsey Markey, Lauren D’Arinzo, Hilke Schellmann, Mona Sloane, Paul Squires, Falaah Arif Khan, and Julia Stoyanovich, ”An External Stability Audit Framework to Test the Validity of Personality Prediction in AI Hiring.” Data Mining and Knowledge Discovery, Special Issue on Bias and Fairness (2022)</a> </p> 

									            	<p> <strong> Github: </strong> <a href="https://github.com/DataResponsibly/hiring-stability-audit"> https://github.com/DataResponsibly/hiring-stability-audit </a> </p>
									            </div>	
									        </div>
									    </div>
									</div>

									<div class="panel panel-default">
									    <div class="panel-heading" role="tab" id="headingTwo">
									        <h4 class="panel-title">
									            <a class="collapsed" data-toggle="collapse" data-parent="#accordion" href="#collapseTwo" aria-expanded="false" aria-controls="collapseTwo">Behavior-based Authentication
									            </a>
									        </h4>
									    </div>
									    <div id="collapseTwo" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingTwo">
									         <div class="panel-body">
									            <div class="row">
										      		<p>The fundamental research problem was to investigate the efficacy of a novel “who I am/how I behave” authentication paradigm. Conventional authentication works on a “what I know” (username/password) or “what I have” (device) model. Our system would study the user’s behavior while typing his/her username and use the activity profile as the key against which access was granted. This eliminated the need for the user to remember a password or have access to a registered device. Conversely, even if a password is cracked or a device is stolen, the bad actor would not be able to penetrate the system because his behavior would intrinsically differ from that of the genuine user.</p>
										      		<p> <strong> Paper: </strong> <a href="https://www.researchgate.net/publication/330582894_Behavioral_Biometrics_and_Machine_Learning_to_Secure_Website_Logins_6th_International_Symposium_SSCC_2018_Bangalore_India_September_19-22_2018_Revised_Selected_Papers"> Arif Khan F., Kunhambu S., G K.C. (2019) Behavioral Biometrics and Machine Learning to Secure Website Logins </a> </p>
										      		<p> <strong> US Patent: </strong> <a href="https://patentimages.storage.googleapis.com/49/0e/5e/484ead387672c6/US20200244639A1.pdf"> Arif Khan, Falaah,  Kunhambu, Sajin and Chakravarthy G, K. Behavioral Biometrics and Machine Learning to secure Website Logins. US Patent 16/257650, filed January 25, 2019 </a> </p>
										      	</div>
									         </div>
									    </div>
									</div>
									
									<div class="panel panel-default">
									    <div class="panel-heading" role="tab" id="headingThree">
									        <h4 class="panel-title">
									            <a class="collapsed" data-toggle="collapse" data-parent="#accordion" href="#collapseThree" aria-expanded="false" aria-controls="collapseThree">Online-Learning for CAPTCHA Optimization
									            </a>
									        </h4>
									    </div>
									    <div id="collapseThree" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingThree">
									        <div class="panel-body">
									            <div class="row">
									            	<p>CAPTCHAs, short for Complete Automated Public Turing Tests to tell Computers and Humans Apart, have been around since 2003 as the simplest human-user identification test. They can be understood as Reverse Turing Tests because in solving a CAPTCHA challenge it is a human subject that is appearing to prove his/her human-ness to a computer program. </p>
									            	<p> Over the years we have seen CAPTCHA challenges evolve from being a string of characters for the user to decipher, to be an image selection challenge, to being as simple as ticking a checkbox. As each new CAPTCHA scheme hits the market, it is inevitably followed with research on new techniques to break these challenges. Engineers must then go back to the drawing board and design a new and more secure CAPTCHA scheme, which, upon deployment and subsequent use, is again, inadvertently subject to adversarial scrutiny. This arduous cycle of designing, breaking and then redesigning to strengthen against subsequent breaking, has become the de-facto lifecycle of a secure CAPTCHA scheme. This beckons the question; Are our CAPTCHAs truly “Completely Automated”? Is the labor involved in designing each new secure scheme outweighed by the speed with which a suitable adversary can be designed? Is the fantasy of creating a truly automated reverse Turing test dead? </p>
									            	<p> Reminding ourselves of why we count CAPTCHAs as such an essential tool in our security toolbox, we characterize CAPTCHAs in a robustness-user experience-feasibility trichotomy. With such a characterization, we introduce a novel framework that leverages Adversarial Learning and Human-in-the-Loop, Bayesian Inference to design CAPTCHAs schemes that are truly automated. We apply our framework to character CAPTCHAs and show that it does in fact generate a scheme that steadily moves closer to our design objectives of maximizing robustness while maintaining user experience and minimizing allocated resources, without requiring manual redesigning. </p>
									            	<p> <strong> US Patent: </strong> <a href="https://patentimages.storage.googleapis.com/ed/af/96/08411a299e082e/US11386193.pdf"> Arif Khan, Falaah and Sharma, Hari Surender. Framework to Design Completely Automated Reverse Turing Tests. US Patent 16/828520, filed March 24, 2020 and US Patent (Provisional) 62/979500, filed February 21, 2020  </a> </p>
									        	</div>
									        </div>
									    </div>
									</div>

								</div>
							</div>
						</div>
					</div>
				</div>
			</section>

			

			<section class="colorlib-gallery" data-section="gallery">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-12">
							<div class="row row-bottom-padded-sm animate-box" data-animate-effect="fadeInLeft">
								<div class="col-md-12">
									<div class="about-desc">
										<span class="heading-meta">Art</span>
						    			<h2 class="colorlib-heading">Machine Learnist Comics</h2>
						    			<a href="https://www.patreon.com/machinelearnist"><img src="images/cover.png" class="img-responsive" alt="Two humans on either side push two spheres towards each other. The intersection of the two spheres, which looks like a classic 2 class Venn diagram has the words 'ML Comics' in it. The person on the left is drawn in pixel art, whereas the person on the right is drawn with a watercolor effect."></a>
						    			<p></p>
						    			<h5> Follow on <a href='https://twitter.com/MachineLearnist'> Twitter </a>, <a href='https://www.facebook.com/TheMachineLearnist'> Facebook, </a> <a href='https://www.instagram.com/themachinelearnist/'> Instagram </a> and support on <a href='https://www.patreon.com/machinelearnist'> Patreon! </a> </h5>
						    			
						    			
						    			<h2 class="colorlib-heading">Latest Volumes!</h2>

						    			<a href="https://www.approximatelycorrect.com/2021/08/10/superheroes-of-deep-learning-vol-2-machine-learning-for-healthcare/"><img src="images/DLHeroes2.png" class="img-responsive" width="600" height="700" alt="DL Heroes 2 cover"></a>
						    			<p></p>
						    			<h5> Falaah Arif Khan and Zachary C. Lipton. “Superheroes of Deep Learning Volume 2: Machine Learning for Healthcare” (August, 2021)</h5>
						    			<p></p>
						    			<p></p>

						    			<a href="http://bit.ly/we-are-ai_comics_vol5_en">
						    			<img src="images/5-cover.png" class="img-responsive" width="600" height="700" alt="We Are AI Cover art."></a>
						    			<p></p>
						    			<h5> Julia Stoyanovich and Falaah Arif Khan. “We are AI”. We are AI Comics, Volume 5 (June, 2021)</h5>
						    			<p></p>
						    			<p></p>

						    			<a href="http://bit.ly/we-are-ai_comics_vol4_en">
						    			<img src="images/4-cover.png" class="img-responsive" width="600" height="700" alt="We Are AI Cover art."></a>
						    			<p></p>
						    			<h5> Julia Stoyanovich and Falaah Arif Khan. “All about that Bias”. We are AI Comics, Volume 4 (June, 2021)</h5>
						    			<p></p>
						    			<p></p>

						    			<a href="http://bit.ly/we-are-ai_comics_vol3_en">
						    			<img src="images/3-cover.png" class="img-responsive" width="600" height="700" alt="We Are AI Cover art."></a>
						    			<p></p>
						    			<h5> Julia Stoyanovich, Mona Sloane and Falaah Arif Khan. “Who lives, who dies, who decides?”. We are AI Comics, Volume 3 (May, 2021)</h5>
						    			<p></p>
						    			<p></p>
						    			
						    			<a href="http://bit.ly/we-are-ai_comics_vol2_en">
						    			<img src="images/2-cover.png" class="img-responsive" width="600" height="700" alt="We Are AI Cover art."></a>
						    			<p></p>
						    			<h5> Julia Stoyanovich and Falaah Arif Khan. “Learning from Data”. We are AI Comics, Volume 2 (May, 2021)</h5>
						    			<p></p>
						    			<p></p>

						    			<a href="http://bit.ly/we-are-aicomicsvol1">
						    			<img src="images/1-cover.png" class="img-responsive" width="600" height="700" alt="We Are AI Cover art."></a>
						    			<p></p>
						    			<h5> Julia Stoyanovich and Falaah Arif Khan. “What is AI?”. We are AI Comics, Volume 1 (May, 2021)</h5>
						    			<p></p>
						    			<p></p>

						    			<a href="https://dataresponsibly.github.io/comics/vol2/fairness_en.pdf">
						    			<img src="images/Fairness_Cover.png" class="img-responsive" width="600" height="700" alt="Artistic depiction of Lady Justice using line and abstract art."></a>
						    			<p></p>
						    			<h5> Falaah Arif Khan, Eleni Manis and Julia Stoyanovich “Fairness and Friends”. Data, Responsibly Comics, Volume 2 (Feb, 2021)</h5>
						    			<p></p>
						    			<p></p>

						    			<a href="https://www.approximatelycorrect.com/2020/10/26/superheroes-of-deep-learning-vol-1-machine-learning-yearning/"><img src="images/DLHeroes1.PNG" class="img-responsive" width="600" height="700" alt="David silver, Andrew ng and Fei Fei li in their superhero form as Q-Silver, MOOC and Benchmark, respectively. Q-Silver is in the middle and is lunging towards the screen. MOOC is to the left and is jumping up into the screen with his arms outstretched and muscles in full display. Benchmark is lunging in cat-like positive to the right. Machine Learning Yearning is written above them."></a>
						    			<p></p>
						    			<h5> Falaah Arif Khan and Zachary C. Lipton. “Superheroes of Deep Learning Volume 1: Machine Learning Yearning” (Oct, 2020) </h5>
						    			<p></p>
						    			<p></p>

						    			<a href="https://dataresponsibly.github.io/comics/"><img src="images/Mirror_Mirror_Cover.png" class="img-responsive" width="600" height="700" alt="Digital painting of a woman, wearing dark sunglasses. In the left pane of the sunglass is the recreation of the cover of the movie Titanic, where Rose is replaced by an android. In the right pane is the painting of the iconic fight scene from Rocky, with the opponent replaced as an Android. The space surrounding the woman has line and abstract art in the shape of flames."></a>
						    			<p></p>
						    			<h5> Falaah Arif Khan and Julia Stoyanovich. “Mirror, Mirror”. Data, Responsibly Comics, Volume 1 (Sept, 2020)</h5>
						    			<p></p>
						    			<p></p>

						    			<a href="https://interactiveaimag.org/columns/articles/comic/meet-ai-comic-vol-1-ed-2/"><img src="images/vol1_cover.png" class="img-responsive" width="600" height="700" alt="Recreation of the last scene of fight club, where the Narrator and Marla stand holding handing as buildings explode around them. In this reimagining of that iconic scene, the narrator is replaced by a humanoid/robot and has the words AI on it's coat"></a>
						    			<p></p>
						    			<h5> Falaah Arif Khan. "Meet AI" (June, 2020). In AAAI Interactive Magazine </h5>						    			
						    			<p></p>


									</div>
								</div>
							</div>
						</div>
					</div>
					<div class="row">
						<div class="col-md-12">
							<div class="row row-bottom-padded-sm animate-box" data-animate-effect="fadeInLeft">
								<div class="col-md-12">
									<div class="about-desc">
										<h2 class="colorlib-heading">Traditional Art</h2>
										<h4> Go to my <a href="https://www.instagram.com/thefaladox/"> Instagram page </a> to see my art! </h4>
						    			<a href="https://www.instagram.com/thefaladox/"><img src="images/collage.png" class="img-responsive" alt="Collage of different artworks in various styles ranging from Polygon art to line art, watercolor, soft pastels, pencil and pen sketch"></a>
						    		</div>
						    	</div>
						    </div>
						</div>
					</div>
				</div>
			</section>



			<section class="colorlib-blog" data-section="blog">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-6 col-md-offset-3 col-md-pull-3 animate-box" data-animate-effect="fadeInLeft">
							<span class="heading-meta">Stuff</span>
							<h2 class="colorlib-heading">Articles, Talks and More!</h2>
						</div>
					</div>

					<div class="row">

						<div class="col-md-4 col-sm-6 animate-box" data-animate-effect="fadeInLeft">
							<div class="blog-entry">
								<a href="https://hayatlife.com/2021/03/17/falaah-arif-khan-ai-comic-interview/" class="blog-img"><img src="images/hayat.PNG" class="img-responsive"></a>
								<div class="desc">
									<span><small>March 17, 2021</small> | <small> Interview </small></span>
									<h3><a href="https://hayatlife.com/2021/03/17/falaah-arif-khan-ai-comic-interview/">Interview with Hayat Life</a></h3>
									<p>I sat down with the folks at Hayat Life to talk about my ML comics - what inspired me to start making them, where I envision them going, and what to expect next! </p>
								</div>
							</div>
						</div>

						<div class="col-md-4 col-sm-6 animate-box" data-animate-effect="fadeInLeft">
							<div class="blog-entry">
								<a href="https://riipl.rutgers.edu/2020/11/10/riipl-algorithmic-justice-webinar-series-11-11-1215/" class="blog-img"><img src="images/riipl.PNG" class="img-responsive"></a>
								<div class="desc">
									<span><small>November 11, 2020</small> | <small> Interview </small></span>
									<h3><a href="https://www.govtech.com/opinion/Comic-Book-Bridges-Gap-Around-Education-in-AI-Ethics.html">RIIPL Algorithmic Justice Webinar Series</a></h3>
									<p>The amazing Julia Stoyanovich and I sat down with Ellen Goodman, from the Rutgers Institute for Information Policy and Law, to discuss the comedic treatment of AI bias, normativity and exclusion, in the context of our 'Data, Responsibly' Comic books! </p>
								</div>
							</div>
						</div>

						<div class="col-md-4 col-sm-6 animate-box" data-animate-effect="fadeInLeft">
							<div class="blog-entry">
								<a href="https://ai-ethics.github.io/decoded-reality/intro.html" class="blog-img"><img src="images/decoded_reality.png" class="img-responsive"></a>
								<div class="desc">
									<span><small>November, 2020</small> | <small> Visual Essay </small></span>
									<h3><a href="https://ai-ethics.github.io/decoded-reality/intro.html">Decoded Reality</a></h3>
									<p>Decoded Reality is a visual essay on the power dynamics that shape the design, development and deployment of ML systems. We present artistic interpretations of how algorithmic interventions manifest in society in the hope of provoking the designers of these systems to think critically about the socio-political underpinnings of each step of the engineering process.</p>
								</div>
							</div>
						</div>
					</div>


					<div class = "row">
						<div class="col-md-4 col-sm-6 animate-box" data-animate-effect="fadeInLeft">
							<div class="blog-entry">
								<a href="https://www.govtech.com/opinion/Comic-Book-Bridges-Gap-Around-Education-in-AI-Ethics.html" class="blog-img"><img src="images/datagov.jpg" class="img-responsive"></a>
								<div class="desc">
									<span><small>September 30, 2020</small> | <small> Interview </small></span>
									<h3><a href="https://www.govtech.com/opinion/Comic-Book-Bridges-Gap-Around-Education-in-AI-Ethics.html">MetroLab "Innovation of the Month" Feature</a></h3>
									<p>"Mirror, Mirror" was featured as the MetroLab Network+ Government Technology "Innovation of the Month". In this interview we discuss the origins of the project, our creative process and the future of Data, Responsibly Comics! </p>
								</div>
							</div>
						</div>

						<div class="col-md-4 col-sm-6 animate-box" data-animate-effect="fadeInLeft">
							<div class="blog-entry">
							<a href="http://approximatelycorrect.com/2020/09/15/hope-returns-to-the-machine-learning-universe/" class="blog-img"><img src="images/Teaser.png" class="img-responsive"></a>
								<div class="desc">
									<span><small>September 15, 2020</small> | <small> Article (Satire) </small> </span>
									<h3><a href="http://approximatelycorrect.com/2020/09/15/hope-returns-to-the-machine-learning-universe/">Hope Returns to the Machine Learning Universe</a></h3>
									<p>According to witnesses, Earth's been visited by the *Superheroes of Deep Learning*. What do they want? What powers do they possess? Will they fight for good or for evil? Read to learn more!.</p>
								</div>	
							</div>
						</div>

						<div class="col-md-4 col-sm-6 animate-box" data-animate-effect="fadeInLeft">
							<div class="blog-entry">
							<a href="https://aihub.org/2020/06/11/interview-with-falaah-arif-khan-talking-security-comics-and-demystifying-the-hype-surrounding-ai/" class="blog-img"><img src="images/comic.png" class="img-responsive"></a>
								<div class="desc">
									<span><small>June 11th, 2020 </small> | <small> Interview </small> </span>
									<h3><a href="https://aihub.org/2020/06/11/interview-with-falaah-arif-khan-talking-security-comics-and-demystifying-the-hype-surrounding-ai/">Interview with AI Hub</a></h3>
									<p>I sat down with the folks at AIHub to chat about my research and art. We talk (meta-)security, scientific comics and demystifying the hype around AI. </p>
								</div>	
							</div>
						</div>				
					</div>


					<div class = "row">
						<div class="col-md-4 col-sm-6 animate-box" data-animate-effect="fadeInLeft">
							<div class="blog-entry">
							<a href="https://thefaladox.wordpress.com/2020/01/04/deep-learning-perspectives-from-death-note-another-approximately-inimitable-exegesis/" class="blog-img"><img src="images/Death_Note.png" class="img-responsive"></a>
								<div class="desc">
									<span><small>January 4, 2020 </small> | <small> Article </small> </span>
									<h3><a href="https://thefaladox.wordpress.com/2020/01/04/deep-learning-perspectives-from-death-note-another-approximately-inimitable-exegesis/">Deep Learning Perspectives from Death Note: Another Approximately Inimitable Exegesis</a></h3>
									<p>Masked under a binge-worthy anime lies an adept critique of the ongoing deep learning craze in the industry. Here’s my commentary on the technical symbols in Death Note.</p>
								</div>	
							</div>
						</div>

						<div class="col-md-4 col-sm-6 animate-box" data-animate-effect="fadeInLeft">
							<div class="blog-entry">
							<a href="https://thefaladox.wordpress.com/2020/07/11/what-is-meta-security/" class="blog-img"><img src="images/metasecurity.png" class="img-responsive"></a>
								<div class="desc">
									<span><small>July 11th, 2020 </small> | <small> Article (Satire) </small> </span>
									<h3><a href="https://thefaladox.wordpress.com/2020/07/11/what-is-meta-security/">What is Meta-Security?</a></h3>
									<p>In this seminal essay, I explain the hottest up and coming sub-field of Machine Learning - Meta-Security!</p>
								</div>	
							</div>
						</div>		
					</div>
				</div>
			</section>


			<section class="colorlib-contact" data-section="contact">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-12">
							<div class="row row-bottom-padded-sm animate-box" data-animate-effect="fadeInLeft">
								<div class="col-md-12">
									<div class="about-desc">
										<span class="heading-meta">Get in Touch</span>
										<h2 class="colorlib-heading">Contact</h2>
										<p>Get in touch if you want to collaborate on an interesting project, want to commission some custom artwork, or simply want to discuss something wonderfully esoteric!</p>
									</div>
								</div>
							</div>
						</div>
					</div>
					<div class="row">
						<div class="col-md-5">
							<div class="colorlib-feature colorlib-feature-sm animate-box" data-animate-effect="fadeInLeft">
								<div class="colorlib-text">
									<p><a href="mailto:fa2161@nyu.edu">Email</a></p>
									<p><a href="https://twitter.com/FalaahArifKhan">Twitter</a></p>
									<p><a href="https://scholar.google.com/citations?hl=en&user=53O3iRgAAAAJ&view_op=list_works&sortby=pubdate">Google Scholar</a></p>
									<p><a href="https://www.linkedin.com/in/falaah-arif-khan-b99058154/">LinkedIn</a></p>
								</div>
							</div>
						</div>
					</div>
				</div>
			</section>

		</div><!-- end:colorlib-main -->
	</div><!-- end:container-wrap -->
	</div><!-- end:colorlib-page -->

	<!-- jQuery -->
	<script src="js/jquery.min.js"></script>
	<!-- jQuery Easing -->
	<script src="js/jquery.easing.1.3.js"></script>
	<!-- Bootstrap -->
	<script src="js/bootstrap.min.js"></script>
	<!-- Waypoints -->
	<script src="js/jquery.waypoints.min.js"></script>
	<!-- Flexslider -->
	<script src="js/jquery.flexslider-min.js"></script>
	<!-- Owl carousel -->
	<script src="js/owl.carousel.min.js"></script>
	<!-- Counters -->
	<script src="js/jquery.countTo.js"></script>
	
	
	<!-- MAIN JS -->
	<script src="js/main.js"></script>

	</body>
</html>

